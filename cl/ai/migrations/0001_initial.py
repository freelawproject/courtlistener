# Generated by Django 6.0.1 on 2026-01-22 01:08

import cl.lib.model_helpers
import cl.lib.storage
import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('contenttypes', '0002_remove_content_type_name'),
    ]

    operations = [
        migrations.CreateModel(
            name='Prompt',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('date_created', models.DateTimeField(auto_now_add=True, db_index=True, help_text='The moment when the item was created.')),
                ('date_modified', models.DateTimeField(auto_now=True, db_index=True, help_text='The last moment when the item was modified. A value in year 1750 indicates the value is unknown')),
                ('name', models.CharField(help_text='Descriptive name for this prompt', max_length=255)),
                ('prompt_type', models.SmallIntegerField(choices=[(1, 'System'), (2, 'User')], default=1, help_text='Whether this is a system or user prompt')),
                ('text', models.TextField(help_text='The actual prompt text sent to the LLM')),
                ('notes', models.TextField(blank=True, help_text='Documentation about purpose, changes, or usage notes')),
                ('is_active', models.BooleanField(default=True, help_text='Whether this prompt is currently active and available for use')),
            ],
            options={
                'verbose_name': 'Prompt',
                'verbose_name_plural': 'Prompts',
            },
        ),
        migrations.CreateModel(
            name='LLMRequest',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('date_created', models.DateTimeField(auto_now_add=True, db_index=True, help_text='The moment when the item was created.')),
                ('date_modified', models.DateTimeField(auto_now=True, db_index=True, help_text='The last moment when the item was modified. A value in year 1750 indicates the value is unknown')),
                ('name', models.CharField(blank=True, help_text="Human-readable request name. e.g., 'Batch run for Jan 20 scans'", max_length=255)),
                ('is_batch', models.BooleanField(default=False, help_text='True if this request groups multiple tasks for a batch API call')),
                ('batch_id', models.CharField(blank=True, help_text='External batch ID from the LLM provider (for batch requests)', max_length=255)),
                ('provider', models.SmallIntegerField(choices=[(1, 'Google Gemini'), (2, 'OpenAI'), (3, 'Anthropic')], default=1, help_text='The LLM provider used for this request')),
                ('api_model_name', models.CharField(blank=True, help_text='Specific model version (e.g., gemini-3-pro-preview, claude-sonnet-4.5)', max_length=100)),
                ('status', models.SmallIntegerField(choices=[(0, 'Unprocessed'), (1, 'In Progress'), (2, 'Succeeded'), (3, 'Failed'), (4, 'Finished')], default=0, help_text='The current status of the request')),
                ('total_tasks', models.IntegerField(default=0, help_text='Total number of tasks in this request')),
                ('completed_tasks', models.IntegerField(default=0, help_text='Number of tasks that have completed successfully')),
                ('failed_tasks', models.IntegerField(default=0, help_text='Number of tasks that have failed')),
                ('max_retries', models.SmallIntegerField(default=3, help_text='Maximum number of retries for failed tasks')),
                ('total_cost_estimate', models.DecimalField(blank=True, decimal_places=4, help_text='Estimated API cost before running', max_digits=10, null=True)),
                ('total_cost_actual', models.DecimalField(blank=True, decimal_places=4, help_text='Actual API cost after completion', max_digits=10, null=True)),
                ('date_started', models.DateTimeField(blank=True, help_text='When request processing began', null=True)),
                ('date_completed', models.DateTimeField(blank=True, help_text='When request processing finished', null=True)),
                ('extra_config_params', models.JSONField(blank=True, default=dict, help_text='JSON object with additional provider-specific parameters (e.g., temperature, max_tokens).')),
                ('batch_response_file', models.FileField(blank=True, help_text='The batch response file from the LLM provider (e.g., a JSONL file)', max_length=1000, storage=cl.lib.storage.IncrementingAWSMediaStorage(), upload_to=cl.lib.model_helpers.make_llm_request_response_file_path)),
                ('prompts', models.ManyToManyField(blank=True, help_text='Prompts used for this request', related_name='requests', to='ai.prompt')),
            ],
            options={
                'verbose_name': 'LLM Request',
                'verbose_name_plural': 'LLM Requests',
            },
        ),
        migrations.CreateModel(
            name='LLMTask',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('date_created', models.DateTimeField(auto_now_add=True, db_index=True, help_text='The moment when the item was created.')),
                ('date_modified', models.DateTimeField(auto_now=True, db_index=True, help_text='The last moment when the item was modified. A value in year 1750 indicates the value is unknown')),
                ('status', models.SmallIntegerField(choices=[(0, 'Unprocessed'), (1, 'In Progress'), (2, 'Succeeded'), (3, 'Failed'), (4, 'Finished')], default=0, help_text='The current status of the task')),
                ('llm_key', models.CharField(help_text='A unique identifier for this task, used to map results back from a batch job.', max_length=255)),
                ('task', models.SmallIntegerField(choices=[(1, 'Extract text from scan'), (2, 'Extract text from scraped documents'), (3, 'Case Name Extraction'), (4, 'Clean Docket Numbers')], help_text='The specific type of operation this task represents.')),
                ('retry_count', models.SmallIntegerField(default=0, help_text='Number of times this task has been retried')),
                ('error_message', models.TextField(blank=True, help_text='Error message if the task failed')),
                ('input_file', models.FileField(blank=True, help_text='The input file to be processed (PDF, text, etc.)', max_length=1000, storage=cl.lib.storage.IncrementingAWSMediaStorage(), upload_to=cl.lib.model_helpers.make_llm_task_input_file_path)),
                ('input_text', models.TextField(blank=True, help_text='Text input for the task, if not using a file.')),
                ('response_file', models.FileField(blank=True, help_text='Full response from the LLM provider stored as a file', max_length=1000, storage=cl.lib.storage.IncrementingAWSMediaStorage(), upload_to=cl.lib.model_helpers.make_llm_task_response_file_path)),
                ('processing_time_ms', models.IntegerField(blank=True, help_text='How long the LLM took to process (milliseconds)', null=True)),
                ('date_started', models.DateTimeField(blank=True, help_text='When processing began', null=True)),
                ('date_completed', models.DateTimeField(blank=True, help_text='When processing finished', null=True)),
                ('object_id', models.PositiveIntegerField(blank=True, help_text='ID of the related object', null=True)),
                ('content_type', models.ForeignKey(blank=True, help_text='Content type of the related object', null=True, on_delete=django.db.models.deletion.CASCADE, to='contenttypes.contenttype')),
                ('request', models.ForeignKey(blank=True, help_text='The LLM request this task belongs to, if any', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='tasks', to='ai.llmrequest')),
            ],
            options={
                'verbose_name': 'LLM Task',
                'verbose_name_plural': 'LLM Tasks',
                'indexes': [models.Index(fields=['content_type', 'object_id'], name='ai_llmtask_content_49d7d1_idx')],
            },
        ),
    ]
